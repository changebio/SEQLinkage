{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c124015-38a8-46be-a326-237dca2cb13e",
   "metadata": {},
   "source": [
    "# Genome-wide Linkage Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd4af0-8cd5-4f18-afd4-3cb0bd167f73",
   "metadata": {},
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173e3c6-d843-43e0-b3e7-b5c6d0a9b6dc",
   "metadata": {},
   "source": [
    "To phase haplotypes from vcfs and run genome-wide linkage analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911ba7b-2d42-46df-94fa-50be23145b6b",
   "metadata": {},
   "source": [
    "### Input\n",
    "\n",
    "\n",
    "- `--cwd`, work directory where the output will be saved to\n",
    "- `--chrom`, including a list of chromosomes\n",
    "    - e.g. `1 2 3`\n",
    "- `--fam-path`, the path of the fam file.\n",
    "- `--vcf-path`, the path of a genotype file in `vcf` format.\n",
    "- `--anno-path`, the path of a annotation file.\n",
    "- `--anno-path`, the path of a sample source file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052f193-d2c4-4b49-8a63-c6921f7a1750",
   "metadata": {},
   "source": [
    "### Output\n",
    "- haplotypes\n",
    "- lods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc2c43-9200-45f1-b1d7-75292e18de16",
   "metadata": {},
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc407d-abb1-4f7a-a4de-5d545b24a451",
   "metadata": {},
   "source": [
    "sos run seqlink_sos.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44e858-6050-4055-901e-c0d30cabd2d7",
   "metadata": {},
   "source": [
    "## Example command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a1bc8-3384-4dcb-83d5-9d4870aa6f2e",
   "metadata": {},
   "source": [
    "### seqlink\n",
    "```\n",
    "sos run nbs/seqlink_sos.ipynb seqlink --cwd data/wg20220316 --fam_path data/new_trim_ped_famless17_no:xx.fam --vcf_path /mnt/mfs/statgen/alzheimers-family/linkage_files/geno/full_sample/vcf/full_sample.vcf.gz --anno_path MWE/annotation --pop_path data/full_sample_fam_pop.txt --chrom 9 10\n",
    "```\n",
    "### linkage\n",
    "```\n",
    "sos run nbs/seqlink_sos.ipynb linkage --cwd data/wg20220316 --fam_path data/new_trim_ped_famless17_no:xx.fam --chrom 1 2 3 4 5 6 7 8\n",
    "```\n",
    "### seqlink and linkage\n",
    "```\n",
    "sos run nbs/seqlink_sos.ipynb --cwd data/wg20220316 --fam_path data/new_trim_ped_famless17_no:xx.fam --vcf_path /mnt/mfs/statgen/alzheimers-family/linkage_files/geno/full_sample/vcf/full_sample.vcf.gz --anno_path MWE/annotation --pop_path data/full_sample_fam_pop.txt --chrom 9 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d87e4d-862f-4f63-96ad-51eb95f7fc6b",
   "metadata": {},
   "source": [
    "## Workflow codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b3459-24a5-49ac-93d9-77fec76b04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory where output will be saved to\n",
    "parameter: cwd = path\n",
    "# Fam file\n",
    "parameter: fam_path = path\n",
    "parameter: chrom = list\n",
    "parameter: walltime = '24h'\n",
    "parameter: mem = '128G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b855c-4212-4c5e-8e40-a358e24b0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[seqlink (phasing haps)]\n",
    "# VCF file\n",
    "parameter: vcf_path = path\n",
    "# annotation path\n",
    "parameter: anno_path = path\n",
    "# Sample source file path\n",
    "parameter: pop_path = path\n",
    "input: fam_path, vcf_path, anno_path, pop_path, for_each = 'chrom'\n",
    "output: f'{cwd:a}/chr{_chrom}test'\n",
    "task: walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = '${ }', stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    \n",
    "    echo \"start\"\n",
    "    seqlink --fam ${fam_path} --vcf ${vcf_path} \\\n",
    "    --anno '${anno_path:a}/EFIGA_NIALOAD_chr${_chrom}.hg38.hg38_multianno.csv' \\\n",
    "    --pop ${pop_path} \\\n",
    "    -o ${_output}  \\\n",
    "    -f 'MERLIN' --build 'hg38' --freq 'AF' --bin 1 --maf-cutoff 0.05 --jobs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90841244-3525-43bf-b006-5ad21db1e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "[rho (cutoffnone rho0)]\n",
    "input: cwd, fam_path, for_each = 'chrom'\n",
    "output: f'{cwd:a}/chr{_chrom}test/tmp/CACHE/chr{_chrom}test'\n",
    "task: trunk_workers = 10, trunk_size=10, walltime = walltime, mem = mem, cores = 10, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = '${ }', stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "\n",
    "    import os.path\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from SEQLinkage.linkage import *\n",
    "    \n",
    "    def run_gene_lods(file,fam,rho=0,cutoff=None):\n",
    "        with open(file+'.pickle', 'rb') as handle:\n",
    "            genes = pickle.load(handle)\n",
    "        gene_variants,gene_fam_haps = format_haps_bunch(genes,fam)\n",
    "        if cutoff is not None:\n",
    "            for f,variants in gene_variants.items():\n",
    "                gene_fam_haps[f]=gene_fam_haps[f].loc[:,[True]*6+list(np.repeat((variants.freqs>cutoff)[variants.uniq],2))]\n",
    "        res = parallel_lods(gene_fam_haps.values(),rho)\n",
    "        smy_res = sum_variant_lods(res)\n",
    "        with open(file+'cutoff'+str(cutoff)+'_rho'+str(rho)+'.result','wb') as handle:\n",
    "            pickle.dump(smy_res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    fam17 = pd.read_csv(f'${fam_path}',delim_whitespace=True,header=None,names=['fid','iid','fathid','mothid','sex','ad'])\n",
    "    fam17.index = list(fam17.iid)\n",
    "    fam17.ad[fam17.ad==-9]=0\n",
    "    fam17_d = {}\n",
    "    for i in fam17.fid.unique():\n",
    "        fam17_d[i] = fam17[fam17.fid==i]\n",
    "    inputs=glob.glob(f'${_input[0]}/chr${_chrom}test/tmp/CACHE/chr${_chrom}test*.pickle')\n",
    "    for i in inputs:\n",
    "        r=0\n",
    "        print(i[:-7],r)\n",
    "        file = i[:-7]+'cutoff'+str(None)+'_rho'+str(r)+'.result'\n",
    "        if os.path.isfile(file):\n",
    "            print('exist! jump',file)\n",
    "        else:\n",
    "            run_gene_lods(i[:-7],fam17_d,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721b5a8-ecd0-4a13-a933-5f984b4ba83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[linkage (linkage analysis)]\n",
    "input: cwd, fam_path, for_each = 'chrom'\n",
    "output: f'{cwd:a}/chr{_chrom}test/tmp/CACHE/chr{_chrom}test'\n",
    "task: walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = '${ }', stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "\n",
    "    import os.path\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from SEQLinkage.linkage import *\n",
    "    \n",
    "    def run_gene_lods(file,fam,rho=0.0,cutoff=None):\n",
    "        with open(file+'.pickle', 'rb') as handle:\n",
    "            genes = pickle.load(handle)\n",
    "        gene_variants,gene_fam_haps = format_haps_bunch(genes,fam)\n",
    "        if cutoff is not None:\n",
    "            for f,variants in gene_variants.items():\n",
    "                gene_fam_haps[f]=gene_fam_haps[f].loc[:,[True]*6+list(np.repeat((variants.freqs>cutoff)[variants.uniq],2))]\n",
    "        res = parallel_lods(gene_fam_haps.values(),rho)\n",
    "        smy_res = sum_variant_lods(res)\n",
    "        with open(file+'cutoff'+str(cutoff)+'_rho'+str(rho)+'.result','wb') as handle:\n",
    "            pickle.dump(smy_res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    fam17 = pd.read_csv(f'${fam_path}',delim_whitespace=True,header=None,names=['fid','iid','fathid','mothid','sex','ad'])\n",
    "    fam17.index = list(fam17.iid)\n",
    "    fam17.ad[fam17.ad==-9]=0\n",
    "    fam17_d = {}\n",
    "    cutoff=0.05\n",
    "    for i in fam17.fid.unique():\n",
    "        fam17_d[i] = fam17[fam17.fid==i]\n",
    "    inputs=glob.glob(f'${_input[0]}/chr${_chrom}test/tmp/CACHE/chr${_chrom}test*.pickle')\n",
    "    for i in inputs:\n",
    "        file=i[:-7]\n",
    "        with open(file+'.pickle', 'rb') as handle:\n",
    "            genes = pickle.load(handle)\n",
    "        gene_variants,gene_fam_haps = format_haps_bunch(genes,fam17_d)\n",
    "        if cutoff is not None:\n",
    "            for f,variants in gene_variants.items():\n",
    "                gene_fam_haps[f]=gene_fam_haps[f].loc[:,[True]*6+list(np.repeat((variants.freqs>cutoff)[variants.uniq],2))]\n",
    "        for r in np.arange(0.0,0.5,0.05):\n",
    "            print(i[:-7],r)\n",
    "            file = i[:-7]+'cutoff'+str(0.05)+'_rho'+str(r)+'.result'\n",
    "            if os.path.isfile(file):\n",
    "                print('exist! jump',file)\n",
    "            else:\n",
    "                res = parallel_lods(gene_fam_haps.values(),r)\n",
    "                smy_res = sum_variant_lods(res)\n",
    "                with open(file+'cutoff'+str(cutoff)+'_rho'+str(r)+'.result','wb') as handle:\n",
    "                    pickle.dump(smy_res, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8aa9a-8c25-48cc-8104-92e63cd20e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[makehap (create hap)]\n",
    "parameter: fam_vcf = path()\n",
    "input: cwd, fam_path, for_each = 'chrom'\n",
    "output: f'{cwd:a}/chr{_chrom}test/tmp/CACHE/chr{_chrom}test'\n",
    "task: walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = '${ }', stderr = f'{_output:n}makehap.stderr', stdout = f'{_output:n}makehap.stdout'\n",
    "\n",
    "    import sys\n",
    "    import os.path\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from SEQLinkage.linkage import *\n",
    "    \n",
    "    def format_haps_by_genes(file,fam,cutoff=None):\n",
    "        with open(file+'.pickle', 'rb') as handle:\n",
    "            genes = pickle.load(handle)\n",
    "        gene_variants,gene_fam_haps = format_haps_bunch(genes,fam)\n",
    "        if cutoff is not None:\n",
    "            for f,variants in gene_variants.items():\n",
    "                gene_fam_haps[f]=gene_fam_haps[f].loc[:,[True]*6+list(np.repeat((variants.freqs>cutoff)[variants.uniq],2))]\n",
    "                variants=variants[variants.freqs>cutoff]\n",
    "        with open(file+'cutoff'+str(cutoff)+'.input','wb') as handle:\n",
    "            pickle.dump([gene_variants,gene_fam_haps], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    if os.path.isfile(f'${fam_vcf}'):\n",
    "        with open(f'${fam_vcf}', 'rb') as handle:\n",
    "            fam17_vcf = pickle.load(handle)\n",
    "    fam17 = pd.read_csv(f'${fam_path}',delim_whitespace=True,header=None,names=['fid','iid','fathid','mothid','sex','ad'])\n",
    "    fam17.index = list(fam17.iid)\n",
    "    fam17.ad[fam17.ad==-9]=0\n",
    "    fam17_d = {}\n",
    "    cutoff=0.05\n",
    "    for i in fam17.fid.unique():\n",
    "        fam17_d[i] = fam17[fam17.fid==i]\n",
    "    inputs=glob.glob(f'${_input[0]}/chr${_chrom}test/tmp/CACHE/chr${_chrom}test*.pickle')\n",
    "    for i in inputs:\n",
    "        file=i[:-7]\n",
    "        output=file+'cutoff'+str(cutoff)+'.input'\n",
    "        if os.path.isfile(output):\n",
    "            print('exist! jump',output,file=sys.stderr)\n",
    "        else:\n",
    "            print('create input',output,file=sys.stdout)\n",
    "            format_haps_by_genes(file,fam17_d,cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d638df5-fe16-4b5f-8efe-04eab012ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[lods (calculate lods)]\n",
    "parameter: fam_vcf = path()\n",
    "input: cwd, fam_path, for_each = 'chrom'\n",
    "output: f'{cwd:a}/chr{_chrom}test/tmp/CACHE/chr{_chrom}test'\n",
    "task: walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = '${ }', stderr = f'{_output:n}lods.stderr', stdout = f'{_output:n}lods.stdout'\n",
    "    \n",
    "    import sys\n",
    "    import os.path\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from SEQLinkage.linkage import *\n",
    "    \n",
    "    if os.path.isfile(f'${fam_vcf}'):\n",
    "        with open(f'${fam_vcf}', 'rb') as handle:\n",
    "            fam17_vcf = pickle.load(handle)\n",
    "    inputs=glob.glob(f'${_input[0]}/chr${_chrom}test/tmp/CACHE/chr${_chrom}test*cutoff0.05.input')\n",
    "    for file in inputs:\n",
    "        if os.path.isfile(f'${fam_vcf}'):\n",
    "            output_file=file[:-6]+'unimputed.lods'\n",
    "        else:\n",
    "            output_file=file[:-6]+'.lods'\n",
    "        if os.path.isfile(output_file):\n",
    "            print('exist! jump',output_file,file=sys.stderr)\n",
    "        else:\n",
    "            print('create input',output_file,file=sys.stdout)\n",
    "            with open(file, 'rb') as handle:\n",
    "                gene_variants,gene_fam_haps = pickle.load(handle)\n",
    "            if os.path.isfile(f'${fam_vcf}'):\n",
    "                for k,hap in gene_fam_haps.items():\n",
    "                    hap.loc[~fam17_vcf[k],[False]*6+[True]*(hap.shape[1]-6)]=0 \n",
    "                    variants=gene_variants[k]\n",
    "                    gene_variants[k]=variants[variants.freqs>0.05]\n",
    "            #remove variants only have 1 or 2\n",
    "            for k in gene_fam_haps.keys():\n",
    "                \n",
    "            res = parallel_lods(gene_fam_haps.values(),np.arange(0,0.5,0.05))\n",
    "            with open(output_file,'wb') as handle:\n",
    "                pickle.dump(res, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83c81b-4d9d-478e-8614-cdc9fea6efab",
   "metadata": {},
   "source": [
    " trunk_workers = 10, trunk_size=10, walltime = walltime, mem = mem, cores = 10, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4d77d-b8d3-4bea-bc25-2aab6f97f422",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "for i in range(1,23):\n",
    "    print(i)\n",
    "    anno = pd.read_csv('../MWE/annotation/EFIGA_NIALOAD_chr'+str(i)+'.hg38.hg38_multianno.csv')\n",
    "    af = anno.AF\n",
    "    af = af.replace('.',0)\n",
    "    af = af.astype(float)\n",
    "    with open('../data/wg20220316/chr'+str(i)+'_common_variants.pickle','wb') as handle:\n",
    "        pickle.dump(anno[af>0.05].Otherinfo1, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f78118-12e7-44e3-9560-80b592efc7cf",
   "metadata": {},
   "source": [
    "sos run nbs/seqlink_sos.ipynb linkage --cwd data/wg20220316 --fam_path data/new_trim_ped_famless17_no:xx.fam --chrom 11 12 13 14 15 16 17 18 19 -j 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576bacd-5870-4705-858f-cb28c1019f45",
   "metadata": {},
   "source": [
    "qsub sos run nbs/seqlink_sos.ipynb linkage --cwd data/wg20220316 --fam_path data/new_trim_ped_famless17_no:xx.fam --chrom 1 2 3 4 5 6 7 8 9 10 -j node1:10 node2:10 node3:10 node4:10 node5:10 node6:10 node7:10 node8:10 node9:10 node10:10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
